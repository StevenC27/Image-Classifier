from mlp import MLP
from dnn import DNN
import helper
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

class_labels = ["Bird", "Cat", "Deer", "Dog", "Horse"]

def mlp(X_train, y_train, X_test, y_test,
        layers=(3072, 1024, 256, 64, 5), epochs=50,
        batch_size=256, grad_clipping=True):
    
    model = MLP(layers=layers, epochs=epochs, grad_clipping=grad_clipping)
    model.fit(X_train, y_train, X_val=X_test, y_val=y_test, batch_size=batch_size)
    y_pred = model.predict(X_test)
    helper.plot_loss_accuracy(model.train_losses, model.val_losses, model.train_accuracies, model.val_accuracies)
    helper.plot_cm(class_labels, y_test, y_pred)
    print(accuracy_score(y_test, y_pred))

# 768, 512, 384, 256, 192, 128, 96, 64, 48, 32, 
def dnn(X_train, y_train, X_test, y_test,
        layers=(3072, 768, 512, 384, 256, 192, 128, 96, 64, 48, 32, 5), epochs=20, lr=0.01, batch_size=256, grad_clipping=True, dropout_rate=0.0, dropout_layers=None, use_augmenting=True, use_bn=True, weight_decay=0.0):
    model = DNN(layers=layers, epochs=epochs, lr=lr, grad_clipping=grad_clipping, dropout_rate=dropout_rate, dropout_layers=dropout_layers, use_augmenting=use_augmenting, use_bn=use_bn, weight_decay=weight_decay)
    model.fit(X_train, y_train, X_test, y_test, batch_size=batch_size)
    y_pred = model.predict(X_test)
    helper.plot_loss_accuracy(model.train_losses, model.val_losses, model.train_accuracies, model.val_accuracies)
    helper.plot_cm(class_labels, y_test, y_pred)
    print(accuracy_score(y_test, y_pred))
    

X_train, y_train, X_test, y_test = helper.get_test_train()

#mlp(X_train, y_train, X_test, y_test, epochs=100, batch_size=256, grad_clipping=True)
#mlp(X_train, y_train, X_test, y_test, epochs=20, batch_size=256, grad_clipping=True)

dnn(X_train, y_train, X_test, y_test, epochs=300, batch_size=256, grad_clipping=True, dropout_rate=0.2, dropout_layers=(3, 5, 7), use_augmenting=True, use_bn=True, weight_decay=1e-4)
plt.show()
